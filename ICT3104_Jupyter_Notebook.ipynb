{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c205650",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aebdb",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "Description: this cell is used for importing the relevant libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae75fb79",
   "metadata": {
    "hide_input": false,
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "tags": [
     "trial"
    ]
   },
   "outputs": [],
   "source": [
    "# Upload File using ipyfilechooser library\n",
    "from ipyfilechooser import FileChooser\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from tqdm.notebook import tqdm, trange\n",
    "# Video Player\n",
    "from IPython.display import Video, display, clear_output\n",
    "import time \n",
    "# Get the root directory of the project\n",
    "from pyprojroot import here\n",
    "# Copy File\n",
    "import shutil\n",
    "# Widget Packages\n",
    "import ipywidgets as widgets\n",
    "# In case widget extension not working\n",
    "# jupyter nbextension enable --py widge|tsnbextension\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# load_dotenv()\n",
    "# os.environ['WANDB_API_KEY'] = os.getenv('WANDB_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cb0ea",
   "metadata": {},
   "source": [
    "Description: This cell is used for opening the file selector for user to select the video as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7459f1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def videoselectorinput():\n",
    "    starting_directory = './data/video'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "def videoselectoroutput():\n",
    "    starting_directory = './pipeline/video/output'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd71b6b",
   "metadata": {},
   "source": [
    "## Pipeline Selection\n",
    "R6(Story): As a user, I want to create appropriate UI elements to allow for switching pipelines so that I can test the different models.\n",
    "\n",
    "### Adding new pipeline\n",
    "To add a new pipeline, add in the name of the pipeline in the options list in the dropdown widgets.\n",
    "\n",
    "T05-157 (Story): As a user, I want to run the pipeline based on the dropdown selected. So that, I can integrate the pipeline dropdown into the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527021f",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Description: This cell is used for setting and opening up the dropdown for the user to select the pipeline. After selecting and clicking \"Confirm\" the code will then run the selected pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205ee99d",
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6a1b775c8d42ea899cc05b41cfba36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Pipeline:', options=('TSU', 'STEP'), value='TSU'), Button(â€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sisters\\source\\repos\\ict3104-team05-2022\\NVIDIA-STEP-MODEL\\STEP\n",
      "Running  STEP  pipeline\n",
      "Loaded dependencies\n"
     ]
    }
   ],
   "source": [
    "#print(os.getcwd())\n",
    "pipelineList = ['TSU', 'STEP']\n",
    "pipelineDropdown = widgets.Dropdown(\n",
    "    options=pipelineList,\n",
    "    value=pipelineList[0],\n",
    "    description='Pipeline:')\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectPipelineSet(b):\n",
    "    if pipelineDropdown.value == \"STEP\":\n",
    "        directory = os.getcwd()\n",
    "        # Use Regex to match STEP\n",
    "        if re.search(r\"TSU\", directory):\n",
    "            %cd ..\n",
    "            path =here(\"./NVIDIA-STEP-MODEL/STEP\")\n",
    "            %cd $path\n",
    "            \n",
    "        elif re.search(r\"STEP\", directory):\n",
    "            pass\n",
    "        else:\n",
    "            path =here(\"./NVIDIA-STEP-MODEL/STEP\")\n",
    "            %cd $path\n",
    "        print(\"Running \" , pipelineDropdown.value, \" pipeline\")\n",
    "        print(\"Loaded dependencies\")\n",
    "        #print(\"Please skip to Section 6 STEP Pipeline\")\n",
    "    elif pipelineDropdown.value == \"TSU\":\n",
    "        directory = os.getcwd()\n",
    "        # Use Regex to match STEP\n",
    "        if re.search(r\"TSU\", directory):\n",
    "            %cd pass\n",
    "        elif re.search(r\"STEP\", directory):\n",
    "            %cd ..\n",
    "            path =here(\"./pipeline\")\n",
    "            %cd $path\n",
    "        else:\n",
    "            path =here(\"./pipeline\")\n",
    "            %cd $path\n",
    "        print(\"Running \" , pipelineDropdown.value, \" pipeline\")\n",
    "        print(\"Loaded dependencies\")\n",
    "        path =here(\"./pipeline\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "pipelineConfirm = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "pipelineConfirm.on_click(selectPipelineSet)\n",
    "pipelineBox = widgets.VBox([widgets.HBox([pipelineDropdown, pipelineConfirm])])\n",
    "pipelineBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b17f71",
   "metadata": {},
   "source": [
    "<a href=\"#STEP\">Click here to go to STEP section</a>\n",
    "<br>\n",
    "<a href=\"#TSU\">Click here to go to TSU section</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b99c7",
   "metadata": {},
   "source": [
    "# Data Exploration Section\n",
    "R2 (Epic): As a user, I want a \"Data Exploration\" section in the notebook so that I can load and display video data from the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed518c9e",
   "metadata": {},
   "source": [
    "## Video Upload / Choose using ipyfilechooser\n",
    "R2 (Story): As a user, I want to upload/choose files from the data folder through an appropriate UI component (E.g. Browse files) in a notebook code cell so that I can pick and choose the video data I would like to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46254d0",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting up the file choosers to select input video and to save output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9251f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9761f",
   "metadata": {},
   "source": [
    "## Upload selected video to the data folder (If needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339780e",
   "metadata": {},
   "source": [
    "Description: This cell is used for uploading the video to data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdc476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload Function\n",
    "# from pyprojroot import here\n",
    "# import shutil\n",
    "def upload(video):\n",
    "    print(video.selected)\n",
    "    source = video.selected\n",
    "    # Source path\n",
    "    # Destination path\n",
    "    destination = (here(\"./data/video\"))\n",
    "\n",
    "    # Copy file from the selected path\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        print(\"File copied successfully.\")\n",
    "\n",
    "    # If source and destination are same\n",
    "    except shutil.SameFileError:\n",
    "        print(\"Source and destination represents the same file.\")\n",
    "\n",
    "    # If destination is a directory.\n",
    "    except IsADirectoryError:\n",
    "        print(\"Destination is a directory.\")\n",
    "\n",
    "    # If there is any permission issue\n",
    "    except PermissionError:\n",
    "        print(\"Permission denied.\")\n",
    "\n",
    "    # For other errors\n",
    "    except:\n",
    "        print(\"Error occurred while copying file.\")\n",
    "\n",
    "upload(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd190ad",
   "metadata": {},
   "source": [
    "## Video Playback\n",
    "R2 (Story): As a user, I want to see video playback of the chosen video file in an output cell so that I can check if it is the right video data I would like to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b00bf6",
   "metadata": {},
   "source": [
    "Description: This cell is used for opening the file selector for user to select video input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce6882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Video\n",
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fea43",
   "metadata": {},
   "source": [
    "Description: This cell is used for printing the details of the selected video (the full path of the video, the name of the video and the directory the video is in). This is for the user to check if it is the same video they selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d5e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(video.selected)\n",
    "print(video.selected_filename)\n",
    "print(video.selected_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73380e7d",
   "metadata": {},
   "source": [
    "Description: This cell is used for running the input video. This is for the user to check if it is the same video they selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09127163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_path = video.selected\n",
    "Video(full_path, embed=True, width=540, html_attributes=\"controls muted autoplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51191d83",
   "metadata": {},
   "source": [
    "<a id='TSU'></a>\n",
    "# Inference Section\n",
    "\n",
    "R3 (Epic): As a user, I want to have an \"Inference\" section in the notebook so that I can perform inference using a pretrained HOI ML model based on the TSU project.\n",
    "<a href='#test'>Link to test</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b56cd",
   "metadata": {},
   "source": [
    "## Load a pretrain model\n",
    "R3 (Story): As a user, I want to load a pre-trained model using an appropriate UI component so that I can easily load the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fb0b0",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting up the dropdown list to allow the user to select the model to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4135",
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select model\n",
    "path =here()\n",
    "os.chdir(path)\n",
    "modelList = [] \n",
    "\n",
    "# Select from the list of model in the pipeline/models folder\n",
    "for x in os.listdir(\"./pipeline/models\"): \n",
    "    modelList += [x]\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "modelDropdown = widgets.Dropdown(\n",
    "    options=modelList,\n",
    "    value=modelList[0],\n",
    "    description='Model:')\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected: \" , modelDropdown.value)\n",
    "\n",
    "confirmButton.on_click(selectWidgetSet)\n",
    "modelBox = widgets.VBox([widgets.HBox([modelDropdown, confirmButton])])\n",
    "modelBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad9e82",
   "metadata": {},
   "source": [
    "## Choose Input video to load into TSU Project\n",
    "R3 (Story): As a user, I want to choose an  input video files and other related input files, using an appropriate UI component, from the TSU project so that the system is able to pass the right files to the model.\n",
    "\n",
    "Take Note: You only can select video that is in **testing subset** on the smarthome_CS_51.json file to run the inference video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054f185",
   "metadata": {},
   "source": [
    "Description: This cell is used for selecting the video input to be passed to the TSU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7e1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Video\n",
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8854da",
   "metadata": {},
   "source": [
    "<a id='test'></a>\n",
    "## Run the model \n",
    "R3 (Story): As a user, I want to see inference results in the form of an output video with captions that indicate the current detected activity in each video frame so that I am able to see the inference results clearly on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c9682",
   "metadata": {},
   "source": [
    "Description: This cell is used for running the inference.py script based on the video and model selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = here(\"./pipeline\")\n",
    "# %cd $path\n",
    "model = modelDropdown.value\n",
    "loadmodel = './models/' + model\n",
    "videoPath = video.selected\n",
    "videoFile = video.selected_filename\n",
    "print(videoFile)\n",
    "print(videoPath)\n",
    "%run -it inference.py  -input_video_file $videoFile -model $model  -load_model $loadmodel -video_path $videoPath\n",
    "%wandb ict3104-team-5/inference-visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326ce9c",
   "metadata": {},
   "source": [
    "## Output Video to view the inference result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c1dc6",
   "metadata": {},
   "source": [
    "Description: This cell is used for print the filepath of the output video. Play the output video below the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb7c95",
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videoFileName = video.selected_filename[:-4]\n",
    "full_path = (os.path.join(here(\"./pipeline/video/output/\"),f\"{videoFileName}_caption.mp4\"))\n",
    "print(full_path)\n",
    "Video(full_path, embed=True, width=540, html_attributes=\"controls muted autoplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935d29c",
   "metadata": {},
   "source": [
    "# Feature Extraction Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c12f9",
   "metadata": {},
   "source": [
    "## Running main feature-extraction function\n",
    "Description: This cell is used for running the main feature-extraction function to extract features from videos listed in video_paths.txt to create RGB .npy files for training later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = here(\"./i3d-feature-extraction\")\n",
    "\n",
    "%cd $path\n",
    "%run -i main.py feature_type=r21d device=\"cuda:0\" on_extraction=save_numpy streams=rgb output_path=./output/RGB_TEST file_with_video_paths=./sample/test_video_paths.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c593e13",
   "metadata": {},
   "source": [
    "## Running validate_train_test.py\n",
    "Description: This cell is used for running validate_train_test.py to remove video IDs from smarthome_cs_51.json file and create an updated version called smarthome_cs_51_v2.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./i3d-feature-extraction && python validate_train_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67463a88",
   "metadata": {},
   "source": [
    "# Training Section\n",
    "R4 (Epic): As a user, I want to create a \"Training\" section in the netbook so that I can train a HOI ML model based on the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70406aa5",
   "metadata": {},
   "source": [
    "## Choose dataset folder to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a634a8",
   "metadata": {},
   "source": [
    "R4 (Story): As a user, I can choose a dataset subfolder, using appropriate UI elements, from the data folder to use for the training so that I can select the data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3270215",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting and opening the dropdown for the user to select the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee4e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Dropdown method\n",
    "path =here()\n",
    "%cd $path\n",
    "dataset_list = []\n",
    "directoryDataset = \"./data/dataset/\" # Directory of the dataset (NPY files)\n",
    "\n",
    "# Store the folder in the  dataset into dataset list\n",
    "for x in os.listdir(directoryDataset):\n",
    "    if os.path.isdir(os.path.join(directoryDataset, x)):\n",
    "        # print(os.path.join(directoryDataset, x))\n",
    "        dataset_list.append(x)\n",
    "\n",
    "datasetDropDown = widgets.Dropdown(\n",
    "    options=dataset_list,\n",
    "    value=dataset_list[0],\n",
    "    description='Dataset:')\n",
    "\n",
    "# Widgets\n",
    "datasetConfirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectDataSet(b):\n",
    "    print(\"Selected Dataset: \" , datasetDropDown.value)\n",
    "   \n",
    "datasetConfirmButton.on_click(selectDataSet)\n",
    "datasetBox = widgets.VBox([widgets.HBox([datasetDropDown, datasetConfirmButton])])\n",
    "datasetBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d35e9",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting and opening up the folder selector to choose the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b18eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Browse folder method\n",
    "def folderSelector():\n",
    "    starting_directory = './data/dataset'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    chooser.show_only_dirs = True\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "\n",
    "datafolder = folderSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e20405",
   "metadata": {},
   "source": [
    "## Run_PDAN.sh for training\n",
    "R4 (Story): As a user, I want to able to change the value for the argument in run_PDAN shell script with a UI so that I does not need to keep changing the value directly in the shell script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ae2eb",
   "metadata": {},
   "source": [
    "Description: This cell is used for form to fill up the parameters needed to run the run_PDAN.sh for training. Running the run_PDAN.sh script based on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10fe28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root_path=here()\n",
    "os.chdir(root_path)\n",
    "title = widgets.Label(\"Run_PDAN\")\n",
    "style = {'description_width': '90px'}\n",
    "\n",
    "dataset_input = widgets.Text(\n",
    "    value='TSU',\n",
    "    placeholder='Enter Dataset Name',\n",
    "    description='Dataset:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "mode_input = widgets.Text(\n",
    "    value='rgb',\n",
    "    placeholder='Enter Mode',\n",
    "    description='Mode:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "split_input = widgets.Text(\n",
    "    value='CS',\n",
    "    placeholder='Enter Split Setting',\n",
    "    description='Split Setting:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "# Using Dropdown method\n",
    "model_list = []\n",
    "directoryModel = \"./pipeline/models\" # Directory of the dataset (NPY files)\n",
    "\n",
    "# Store the folder in the  dataset into dataset list\n",
    "for x in os.listdir(directoryModel):\n",
    "    if os.path.isdir(os.path.join(directoryModel, x)) == False:\n",
    "        model_list.append(x)\n",
    "        \n",
    "model_input = widgets.Dropdown(\n",
    "    options=model_list,\n",
    "    value=model_list[0],\n",
    "    description='Model:',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "\n",
    "train_input = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description = 'Train',\n",
    "    disabled=False,\n",
    "    indent=True,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "num_channel_input =  widgets.BoundedIntText(\n",
    "    value=512,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Num Channel:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "lr_input = widgets.FloatText(\n",
    "    value=0.0002,\n",
    "    description='Learning Rate:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "kernel_size_input =  widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=5,\n",
    "    step=1,\n",
    "    description='Kernel Size:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "aptype_input = widgets.Text(\n",
    "    value='map',\n",
    "    placeholder='Enter APType',\n",
    "    description='APType:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "epoch_input = widgets.BoundedIntText(\n",
    "    value=140,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Epoch:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "batch_size_input = widgets.Dropdown(\n",
    "    options=['1', '2', '4', '8', '16', '32', '64', '128', '256', '512', '1024'],\n",
    "    value='1',\n",
    "    description='Batch_Size:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "\n",
    "comp_info_input = widgets.Text(\n",
    "    value='TSU_CS_RGB_PDAN',\n",
    "    placeholder='Enter Compute Info',\n",
    "    description='Compute Info:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Save',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Save Pref',\n",
    "    icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "    style=style\n",
    ")\n",
    "\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected Dataset: \" , dataset_input.value)\n",
    "    print(\"Selected Mode: \" , mode_input.value)\n",
    "    print(\"Selected Split Setting: \" , split_input.value)\n",
    "    print(\"Selected Model: \" , model_input.value)\n",
    "    print(\"Selected Train: \" , train_input.value)\n",
    "    print(\"Selected Num Channel: \" , num_channel_input.value)\n",
    "    print(\"Selected Learning Rate: \" , lr_input.value)\n",
    "    print(\"Selected Kernel Size: \" , kernel_size_input.value)\n",
    "    print(\"Selected APType: \", aptype_input.value)\n",
    "    print(\"Selected Epoch: \", epoch_input.value)\n",
    "    print(\"Selected Batch: \" , batch_size_input.value)\n",
    "    print(\"Selected Compute Info: \" , comp_info_input.value)\n",
    "    path =here(\"./pipeline\")\n",
    "    %cd $path\n",
    "    dataset_path = os.path.join(\"../data/dataset/\" , datasetDropDown.value)\n",
    "    print(\"Dataset Path: \", dataset_path)\n",
    "    %run -i train.py -dataset $dataset_input.value -mode $mode_input.value -split_setting $split_input.value -model $model_input.value -train $train_input.value -num_channel $num_channel_input.value -lr $lr_input.value -kernelsize $kernel_size_input.value -APtype $aptype_input.value -epoch $epoch_input.value -batch_size $batch_size_input.value -comp_info $comp_info_input.value -input_folder $dataset_path \n",
    "    %wandb ict3104-team-5/training-visualisation\n",
    "    \n",
    "display(title, dataset_input, mode_input,split_input, model_input, train_input, num_channel_input, lr_input, kernel_size_input, aptype_input, epoch_input, batch_size_input, comp_info_input ,button)\n",
    "button.on_click(selectWidgetSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d60d71",
   "metadata": {},
   "source": [
    "# To be integrated\n",
    "R4 (Story): As a user, I can add the trained model to the list of pre-trained models that can be chosen in R3 after its training so that I can add my trained model to pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff9735",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting and opening up the dropdown to allow the user to choose whether to add or remove the model from a list of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =here(\"\")\n",
    "%cd $path\n",
    "change_list = ['Add', 'Remove']\n",
    "\n",
    "confirmChangeButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "modelChangeDropDown = widgets.Dropdown(\n",
    "    options=change_list,\n",
    "    description='Add/Remove: ')\n",
    "\n",
    "def selectChangeSet(b):\n",
    "    global choice\n",
    "    choice = modelChangeDropDown.value\n",
    "    print(\"Selected: \" , modelChangeDropDown.value)\n",
    "    \n",
    "confirmChangeButton.on_click(selectChangeSet)\n",
    "display(modelChangeDropDown, confirmChangeButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac09381",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting and opening up the filechooser to select the model to be added to or removed from the list of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af76479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addModel():\n",
    "    starting_directory = '.'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "\n",
    "#pretrained_models = ['TSU_', 'NVIDIA Setp Model']\n",
    "pretrained_models = []\n",
    "\n",
    "add_model = addModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aac222",
   "metadata": {},
   "source": [
    "Description: This cell is used for adding or removing the model to/from the list of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_file(add_model):\n",
    "    if add_model.selected_filename == None:\n",
    "        return  ''\n",
    "    else:\n",
    "        from pathlib import Path\n",
    "        file_name = Path(add_model.selected_filename).stem\n",
    "        return file_name\n",
    "    \n",
    "file_name = selected_file (add_model)\n",
    "\n",
    "#models_list = ['TSU', 'NVIDIA Set Model']\n",
    "models_list = []\n",
    "\n",
    "def checkExist(filename):\n",
    "    with open('models_list.txt', 'r') as f:\n",
    "        if filename in f.read():\n",
    "            f.close()\n",
    "            return True\n",
    "        else:\n",
    "            f.close()\n",
    "            return False\n",
    "        \n",
    "def addToList(filename):\n",
    "    if checkExist(filename):\n",
    "        print(filename, \" already exist\")\n",
    "    else:\n",
    "         with open('models_list.txt', 'a') as f:\n",
    "            f.write(filename + \"\\n\")\n",
    "            \n",
    "def removeFromList(filename):\n",
    "    if checkExist(filename):\n",
    "        with open('models_list.txt', 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "\n",
    "        # Delete text and Write\n",
    "        with open('models_list.txt', 'w') as file:\n",
    "            # Delete\n",
    "            new_text = text.replace(filename, '')\n",
    "            # Write\n",
    "            file.write(new_text)\n",
    "    else:\n",
    "        print(filename, \" does not exist\")\n",
    "    \n",
    "    \n",
    "if choice == 'Add':\n",
    "    addToList(file_name)\n",
    "elif choice == 'Remove':\n",
    "    removeFromList(file_name)\n",
    "else:\n",
    "    print('Invalid choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba99aa7",
   "metadata": {},
   "source": [
    "# Testing Section\n",
    "R5 (Epic): As a user, I want to have a \"Testing\" section in the notebook so that I can evaluate a trained model based on the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bfc3b",
   "metadata": {},
   "source": [
    "R5 (Story): As a user, I want to load a pretrained model using an appropriate UI component so that I can easily choose the type of pretrained model I would like to process the data with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87d280",
   "metadata": {},
   "source": [
    "Description: This cell is used for dropdown for the user to select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model\n",
    "modelList = [] \n",
    "\n",
    "# Select from the list of model in the pipeline/models folder\n",
    "for x in os.listdir(\"./pipeline/models\"): \n",
    "    modelList += [x]\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "modelDropdown = widgets.Dropdown(\n",
    "    options=modelList,\n",
    "    value=modelList[0],\n",
    "    description='Model:')\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected: \" , modelDropdown.value)\n",
    "\n",
    "confirmButton.on_click(selectWidgetSet)\n",
    "modelBox = widgets.VBox([widgets.HBox([modelDropdown, confirmButton])])\n",
    "modelBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b674a8",
   "metadata": {},
   "source": [
    "# Testing Section\n",
    "R5 (Epic): As a user, I want to have a \"Testing\" section in the notebook so that I can evaluate a trained model based on the TSU project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31541446",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =here(\"./pipeline\")\n",
    "%cd $path\n",
    "\n",
    "%run -i test.py -split CS -pkl_path \"models/\"$modelDropdown.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143aac1",
   "metadata": {},
   "source": [
    "# NVIDIA STEP Section\n",
    "R6 (Epic): As a user, I want to able to configure the notebook using appropriate UI elements coupled with the right .py modules so that R2-5 can be performed based on another pipeline, e.g., the NVIDIA STEP pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58612b38",
   "metadata": {},
   "source": [
    "<a id='STEP'></a>\n",
    "## Nvidia Step Pipeline\n",
    "R6(Story): As a user, I want to ensure selected pipeline's dependencies are changed to ensure the right dependencies are given to the appropriate models so that the selected model will be run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bc6f4",
   "metadata": {},
   "source": [
    "Description: This cell is used for setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12f59e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Else run this\n",
    "%run -i setup.py build develop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7806",
   "metadata": {},
   "source": [
    "Description: This cell is used for displaying the first frame of the processed video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78fe48",
   "metadata": {},
   "source": [
    "T05-128: As a User, I want pre-process the input video into frames for Nvidia STEP model, So that I can run the model successfully.\n",
    "\n",
    "T05-127 As a User, I want the output of Nvidia STEP model to be in a video format, So that I can easily view the results of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a7bbc",
   "metadata": {},
   "source": [
    "T05-119: As a user, I want to have multiple dropdowns to select the input (1) dataset (2) video so that I can select the dataset videos easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0728041",
   "metadata": {},
   "source": [
    "Description: This cell is used for setting and  opening up the dropdowns to allow user to select the dataset and the video input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18281ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8804116078dc46148d331bde633d4530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset:', options=('.ipynb_checkpoints', '1'), value='.ipynb_checkpoints')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3554846029c40e7addb72b11c93ae94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video: ', options=('1.mp4',), value='1.mp4')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee070401e6ca4c39a03f13cf6b3989c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Confirm', icon='check', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Dataset:  1\n",
      "Selected Video:  1.mp4\n"
     ]
    }
   ],
   "source": [
    "# Select video\n",
    "video_list = [] \n",
    "dataset_list = [] \n",
    "directoryVideo = \"./Input/\" # Directory of the video (.mp4)\n",
    "directoryDataset = \"./datasets/demo/frames/\" # Directory of the dataset (NPY files)\n",
    "\n",
    "# Store the folder in the  dataset into dataset list\n",
    "for x in os.listdir(directoryDataset):\n",
    "    if os.path.isdir(os.path.join(directoryDataset, x)):\n",
    "        # print(os.path.join(directoryDataset, x))\n",
    "        dataset_list.append(x)\n",
    "\n",
    "# Store the video names into video list\n",
    "for x in os.listdir(directoryVideo):\n",
    "    if x.endswith(\".mp4\"):\n",
    "        video_list.append(x)\n",
    "\n",
    "datasetDropDown = widgets.Dropdown(\n",
    "    options=dataset_list,\n",
    "    description='Dataset:')\n",
    "\n",
    "videoDropDown = widgets.Dropdown(\n",
    "    options=video_list,\n",
    "    description='Video: ')\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "# Function on what happen when confirm is been click. To be intergrated with some other code\n",
    "def selectTrimSet(b):\n",
    "    print(\"Selected Dataset: \" , datasetDropDown.value)\n",
    "    print(\"Selected Video: \" , videoDropDown.value)\n",
    "\n",
    "confirmButton.on_click(selectTrimSet)\n",
    "display(datasetDropDown, videoDropDown, confirmButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1ba03",
   "metadata": {},
   "source": [
    "Description: This cell is used to caption every frame of the video. Afterwards, it will run the STEP Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "cap= cv2.VideoCapture('Input/' + videoDropDown.value)\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('datasets/demo/frames/' + datasetDropDown.value + '/frame'+str(i).zfill(4)+'.jpg',frame)\n",
    "    i+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## Traubung code will be here\n",
    "%run -i demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d9f6d",
   "metadata": {},
   "source": [
    "Description: This cell is used for reading every frames in the results folder.It will write the captions of the frames onto the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9872d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "img_array = []\n",
    "for filename in glob.glob('datasets/demo/results/' + datasetDropDown.value + '/*.jpg'):\n",
    "    img = cv2.imread(filename) \n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('Output/demo-result.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ee6ec",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbfd998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014eac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./scripts/generate_label.py \"datasets/ava/label/ava_train_v2.1.csv\" \n",
    "%run ./scripts/generate_label.py \"datasets/ava/label/ava_val_v2.1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72af6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./scripts/extract_clips.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a30ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_root=\"datasets/ava/\"\n",
    "save_root=\"datasets/ava/cache/\"\n",
    "pretrain_path=\"pretrained/ava_step.pth\"\n",
    "\n",
    "name=\"STEP\"\n",
    "base_net=\"i3d\"\n",
    "det_net=\"two_branch\"\n",
    "resume_path=\"Auto\"\n",
    "\n",
    "T=3\n",
    "max_iter=3    # index starts from 1\n",
    "iterative_mode=\"temporal\"\n",
    "anchor_mode=\"1\"\n",
    "temporal_mode=\"predict\"\n",
    "pool_mode=\"align\"\n",
    "pool_size=7\n",
    "\n",
    "# training schedule\n",
    "num_workers=1\n",
    "max_epochs=14\n",
    "batch_size=1\n",
    "optimizer=\"adam\"\n",
    "base_lr=7.5e-5\n",
    "det_lr0=1.5e-4\n",
    "det_lr=7.5e-4\n",
    "save_step=11465\n",
    "print_step=500\n",
    "scheduler=\"cosine\"\n",
    "milestones=\"-1\"\n",
    "warmup_iters=1000\n",
    "\n",
    "# losses\n",
    "dropout=0.3\n",
    "fc_dim=256\n",
    "lambda_reg=5\n",
    "lambda_neighbor=1\n",
    "cls_thresh=\"0.2,0.35,0.5\"\n",
    "reg_thresh=\"0.2,0.35,0.5\"\n",
    "max_pos_num=5\n",
    "neg_ratio=2\n",
    "NUM_SAMPLE=-1\n",
    "topk=300\n",
    "evaluate_topk=300\n",
    "\n",
    "# data augmentation / normalization\n",
    "scale_norm=2    # for i3d\n",
    "do_flip=\"True\"\n",
    "do_crop=\"True\"\n",
    "do_photometric=\"True\"\n",
    "do_erase=\"True\"\n",
    "freeze_affine=\"True\"\n",
    "freeze_stats=\"True\"\n",
    "\n",
    "\n",
    "%run train.py --data_root $data_root --save_root $save_root \\\n",
    "    --name $name --pretrain_path $pretrain_path --resume_path $resume_path \\\n",
    "    --base_net $base_net --det_net $det_net --max_iter $max_iter --T $T \\\n",
    "    --iterative_mode $iterative_mode --anchor_mode $anchor_mode --anchor_mode $anchor_mode --temporal_mode $temporal_mode \\\n",
    "    --pool_mode $pool_mode --pool_size $pool_size --save_step $save_step --topk $topk --evaluate_topk $evaluate_topk \\\n",
    "    --num_workers $num_workers --max_epochs $max_epochs --batch_size $batch_size --print_step $print_step \\\n",
    "    --optimizer $optimizer --base_lr $base_lr --det_lr $det_lr --det_lr0 $det_lr0 --milestones $milestones \\\n",
    "    --scale_norm $scale_norm --do_flip $do_flip --do_crop $do_crop --do_photometric $do_photometric --do_erase $do_erase \\\n",
    "    --fc_dim $fc_dim --dropout $dropout --NUM_SAMPLE $NUM_SAMPLE --scheduler $scheduler --warmup_iters $warmup_iters \\\n",
    "    --cls_thresh $cls_thresh --reg_thresh $reg_thresh --max_pos_num $max_pos_num --neg_ratio $neg_ratio \\\n",
    "    --freeze_affine $freeze_affine --freeze_stats $freeze_stats --lambda_reg $lambda_reg --lambda_neighbor $lambda_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a23aa5",
   "metadata": {},
   "source": [
    "## STEP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a343fb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: If you want to use fp16, please apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0\n",
      "Warning: If you want to use fp16, please apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0\n",
      "Warning: If you want to use fp16, please apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0\n",
      "Loading pretrain model from pretrained/ava_step.pth\n",
      "Building I3D model...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for context branch...\n",
      "test set | Datalist len:  897\n",
      "100 / 112\n",
      "200 / 112\n",
      "300 / 112\n",
      "400 / 112\n",
      "{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/answer phone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.12772828538669556,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.530668781604834,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/climb (e.g., a mountain)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/close (e.g., a door, a box)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dress/put on clothing': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drink': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drive (e.g., a car, a truck)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/eat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/enter': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fight/hit (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/get up': 0.08333333333333333,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/give/serve (an object) to (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/grab (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand clap': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand shake': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand wave': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hit (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hug (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/jump/leap': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/kiss (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift/pick up': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen (e.g., to music)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.4369392723397072,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/martial art': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/open (e.g., a window, a car door)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/play musical instrument': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/point to (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pull (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (another person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/put down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/read': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/run/jog': 0.6833333333333335,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sail boat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/shoot': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sing to (e.g., self, a person, a group)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.708950545115035,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/smoke': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand': 0.7488984531950846,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/swim': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take (an object) from (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take a photo': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.9215612579070309,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/text on/look at a cellphone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/throw': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.09353150619969877,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/turn (e.g., a screwdriver)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.6259977537667479,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.32906570385204753,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (e.g., TV)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/work on a computer': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/write': nan,\n",
      "  'PascalBoxes_Precision/mAP@0.5IOU': 0.3526672150689032}\n",
      "{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/answer phone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.1678070336733541,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.6235630006218564,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/climb (e.g., a mountain)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/close (e.g., a door, a box)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dress/put on clothing': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drink': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drive (e.g., a car, a truck)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/eat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/enter': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fight/hit (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/get up': 0.3333333333333333,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/give/serve (an object) to (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/grab (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand clap': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand shake': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand wave': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hit (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hug (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/jump/leap': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/kiss (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift/pick up': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen (e.g., to music)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.5129506806802846,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/martial art': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/open (e.g., a window, a car door)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/play musical instrument': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/point to (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pull (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (another person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/put down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/read': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/run/jog': 0.6124999999999999,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sail boat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/shoot': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sing to (e.g., self, a person, a group)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.7475715891506615,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/smoke': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand': 0.8157960945248073,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/swim': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take (an object) from (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take a photo': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.9320389235191142,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/text on/look at a cellphone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/throw': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.10133555186217139,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/turn (e.g., a screwdriver)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.8061484478582288,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.36156264854773246,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (e.g., TV)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/work on a computer': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/write': nan,\n",
      "  'PascalBoxes_Precision/mAP@0.5IOU': 0.40097382025143624}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/answer phone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.16301131607798275,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.6331489696437311,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/climb (e.g., a mountain)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/close (e.g., a door, a box)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dress/put on clothing': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drink': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drive (e.g., a car, a truck)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/eat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/enter': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fight/hit (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/get up': 0.16666666666666666,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/give/serve (an object) to (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/grab (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand clap': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand shake': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand wave': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hit (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hug (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/jump/leap': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/kiss (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift/pick up': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen (e.g., to music)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.5256766255868928,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/martial art': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/open (e.g., a window, a car door)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/play musical instrument': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/point to (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pull (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (another person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/put down': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/read': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/run/jog': 0.6513888888888888,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sail boat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/shoot': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sing to (e.g., self, a person, a group)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.7651825251034422,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/smoke': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand': 0.8212031990600164,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/swim': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take (an object) from (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take a photo': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.933168517762098,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/text on/look at a cellphone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/throw': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.10543665789439201,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/turn (e.g., a screwdriver)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.8050682538566304,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.3434069656764268,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (e.g., TV)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/work on a computer': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/write': nan,\n",
      "  'PascalBoxes_Precision/mAP@0.5IOU': 0.3942239057478112}\n"
     ]
    }
   ],
   "source": [
    "%run test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc27548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain model from pretrained/trained.pth\n",
      "Building I3D model...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for global branch...\n",
      "Building I3D head for context branch...\n",
      "Datalist len:  496\n",
      "{'video_name': '1', 'fid': 0}\n",
      "{'video_name': '1', 'fid': 1}\n",
      "{'video_name': '1', 'fid': 2}\n",
      "{'video_name': '1', 'fid': 3}\n",
      "Batch time:  11.116803169250488\n",
      "{'video_name': '1', 'fid': 4}\n",
      "{'video_name': '1', 'fid': 5}\n",
      "{'video_name': '1', 'fid': 6}\n",
      "{'video_name': '1', 'fid': 7}\n",
      "Batch time:  6.138178586959839\n",
      "{'video_name': '1', 'fid': 8}\n",
      "{'video_name': '1', 'fid': 9}\n",
      "{'video_name': '1', 'fid': 10}\n",
      "{'video_name': '1', 'fid': 11}\n",
      "Batch time:  5.797192573547363\n",
      "{'video_name': '1', 'fid': 12}\n",
      "{'video_name': '1', 'fid': 13}\n",
      "{'video_name': '1', 'fid': 14}\n",
      "{'video_name': '1', 'fid': 15}\n",
      "Batch time:  5.69916296005249\n",
      "{'video_name': '1', 'fid': 16}\n",
      "{'video_name': '1', 'fid': 17}\n",
      "{'video_name': '1', 'fid': 18}\n",
      "{'video_name': '1', 'fid': 19}\n",
      "Batch time:  5.591772794723511\n",
      "{'video_name': '1', 'fid': 20}\n",
      "{'video_name': '1', 'fid': 21}\n",
      "{'video_name': '1', 'fid': 22}\n",
      "{'video_name': '1', 'fid': 23}\n",
      "Batch time:  5.932257652282715\n",
      "{'video_name': '1', 'fid': 24}\n",
      "{'video_name': '1', 'fid': 25}\n",
      "{'video_name': '1', 'fid': 26}\n",
      "{'video_name': '1', 'fid': 27}\n",
      "Batch time:  6.194011449813843\n",
      "{'video_name': '1', 'fid': 28}\n",
      "{'video_name': '1', 'fid': 29}\n",
      "{'video_name': '1', 'fid': 30}\n",
      "{'video_name': '1', 'fid': 31}\n",
      "Batch time:  5.847706079483032\n",
      "{'video_name': '1', 'fid': 32}\n",
      "{'video_name': '1', 'fid': 33}\n",
      "{'video_name': '1', 'fid': 34}\n",
      "{'video_name': '1', 'fid': 35}\n",
      "Batch time:  5.820163249969482\n",
      "{'video_name': '1', 'fid': 36}\n",
      "{'video_name': '1', 'fid': 37}\n",
      "{'video_name': '1', 'fid': 38}\n",
      "{'video_name': '1', 'fid': 39}\n",
      "Batch time:  5.9274656772613525\n",
      "{'video_name': '1', 'fid': 40}\n",
      "{'video_name': '1', 'fid': 41}\n",
      "{'video_name': '1', 'fid': 42}\n",
      "{'video_name': '1', 'fid': 43}\n",
      "Batch time:  5.878951787948608\n",
      "{'video_name': '1', 'fid': 44}\n",
      "{'video_name': '1', 'fid': 45}\n",
      "{'video_name': '1', 'fid': 46}\n",
      "{'video_name': '1', 'fid': 47}\n",
      "Batch time:  5.8568785190582275\n",
      "{'video_name': '1', 'fid': 48}\n",
      "{'video_name': '1', 'fid': 49}\n",
      "{'video_name': '1', 'fid': 50}\n",
      "{'video_name': '1', 'fid': 51}\n",
      "Batch time:  5.832942247390747\n",
      "{'video_name': '1', 'fid': 52}\n",
      "{'video_name': '1', 'fid': 53}\n",
      "{'video_name': '1', 'fid': 54}\n",
      "{'video_name': '1', 'fid': 55}\n",
      "Batch time:  5.915701389312744\n",
      "{'video_name': '1', 'fid': 56}\n",
      "{'video_name': '1', 'fid': 57}\n",
      "{'video_name': '1', 'fid': 58}\n",
      "{'video_name': '1', 'fid': 59}\n",
      "Batch time:  5.788335561752319\n",
      "{'video_name': '1', 'fid': 60}\n",
      "{'video_name': '1', 'fid': 61}\n",
      "{'video_name': '1', 'fid': 62}\n",
      "{'video_name': '1', 'fid': 63}\n",
      "Batch time:  5.741254568099976\n",
      "{'video_name': '1', 'fid': 64}\n",
      "{'video_name': '1', 'fid': 65}\n",
      "{'video_name': '1', 'fid': 66}\n",
      "{'video_name': '1', 'fid': 67}\n",
      "Batch time:  5.921334981918335\n",
      "{'video_name': '1', 'fid': 68}\n",
      "{'video_name': '1', 'fid': 69}\n",
      "{'video_name': '1', 'fid': 70}\n",
      "{'video_name': '1', 'fid': 71}\n",
      "Batch time:  5.484443187713623\n",
      "{'video_name': '1', 'fid': 72}\n",
      "{'video_name': '1', 'fid': 73}\n",
      "{'video_name': '1', 'fid': 74}\n",
      "{'video_name': '1', 'fid': 75}\n",
      "Batch time:  5.8103625774383545\n",
      "{'video_name': '1', 'fid': 76}\n",
      "{'video_name': '1', 'fid': 77}\n",
      "{'video_name': '1', 'fid': 78}\n",
      "{'video_name': '1', 'fid': 79}\n",
      "Batch time:  5.717646598815918\n",
      "{'video_name': '1', 'fid': 80}\n",
      "{'video_name': '1', 'fid': 81}\n",
      "{'video_name': '1', 'fid': 82}\n",
      "{'video_name': '1', 'fid': 83}\n",
      "Batch time:  5.757940292358398\n",
      "{'video_name': '1', 'fid': 84}\n",
      "{'video_name': '1', 'fid': 85}\n",
      "{'video_name': '1', 'fid': 86}\n",
      "{'video_name': '1', 'fid': 87}\n",
      "Batch time:  5.687567234039307\n",
      "{'video_name': '1', 'fid': 88}\n",
      "{'video_name': '1', 'fid': 89}\n",
      "{'video_name': '1', 'fid': 90}\n",
      "{'video_name': '1', 'fid': 91}\n",
      "Batch time:  5.7699315547943115\n",
      "{'video_name': '1', 'fid': 92}\n",
      "{'video_name': '1', 'fid': 93}\n",
      "{'video_name': '1', 'fid': 94}\n",
      "{'video_name': '1', 'fid': 95}\n",
      "Batch time:  5.846991062164307\n",
      "{'video_name': '1', 'fid': 96}\n",
      "{'video_name': '1', 'fid': 97}\n",
      "{'video_name': '1', 'fid': 98}\n",
      "{'video_name': '1', 'fid': 99}\n",
      "Batch time:  5.986087799072266\n",
      "{'video_name': '1', 'fid': 100}\n",
      "{'video_name': '1', 'fid': 101}\n",
      "{'video_name': '1', 'fid': 102}\n",
      "{'video_name': '1', 'fid': 103}\n",
      "Batch time:  5.655888795852661\n",
      "{'video_name': '1', 'fid': 104}\n",
      "{'video_name': '1', 'fid': 105}\n",
      "{'video_name': '1', 'fid': 106}\n",
      "{'video_name': '1', 'fid': 107}\n",
      "Batch time:  5.910982608795166\n",
      "{'video_name': '1', 'fid': 108}\n",
      "{'video_name': '1', 'fid': 109}\n",
      "{'video_name': '1', 'fid': 110}\n",
      "{'video_name': '1', 'fid': 111}\n",
      "Batch time:  5.993938684463501\n",
      "{'video_name': '1', 'fid': 112}\n",
      "{'video_name': '1', 'fid': 113}\n",
      "{'video_name': '1', 'fid': 114}\n",
      "{'video_name': '1', 'fid': 115}\n",
      "Batch time:  5.601754188537598\n",
      "{'video_name': '1', 'fid': 116}\n",
      "{'video_name': '1', 'fid': 117}\n",
      "{'video_name': '1', 'fid': 118}\n",
      "{'video_name': '1', 'fid': 119}\n",
      "Batch time:  5.765796184539795\n",
      "{'video_name': '1', 'fid': 120}\n",
      "{'video_name': '1', 'fid': 121}\n",
      "{'video_name': '1', 'fid': 122}\n",
      "{'video_name': '1', 'fid': 123}\n",
      "Batch time:  5.507725715637207\n",
      "{'video_name': '1', 'fid': 124}\n",
      "{'video_name': '1', 'fid': 125}\n",
      "{'video_name': '1', 'fid': 126}\n",
      "{'video_name': '1', 'fid': 127}\n",
      "Batch time:  5.496081352233887\n",
      "{'video_name': '1', 'fid': 128}\n",
      "{'video_name': '1', 'fid': 129}\n",
      "{'video_name': '1', 'fid': 130}\n",
      "{'video_name': '1', 'fid': 131}\n",
      "Batch time:  5.715389251708984\n",
      "{'video_name': '1', 'fid': 132}\n",
      "{'video_name': '1', 'fid': 133}\n",
      "{'video_name': '1', 'fid': 134}\n",
      "{'video_name': '1', 'fid': 135}\n",
      "Batch time:  5.356832027435303\n",
      "{'video_name': '1', 'fid': 136}\n",
      "{'video_name': '1', 'fid': 137}\n",
      "{'video_name': '1', 'fid': 138}\n",
      "{'video_name': '1', 'fid': 139}\n",
      "Batch time:  5.710923194885254\n",
      "{'video_name': '1', 'fid': 140}\n",
      "{'video_name': '1', 'fid': 141}\n",
      "{'video_name': '1', 'fid': 142}\n",
      "{'video_name': '1', 'fid': 143}\n",
      "Batch time:  5.711620569229126\n",
      "{'video_name': '1', 'fid': 144}\n",
      "{'video_name': '1', 'fid': 145}\n",
      "{'video_name': '1', 'fid': 146}\n",
      "{'video_name': '1', 'fid': 147}\n",
      "Batch time:  5.594310522079468\n",
      "{'video_name': '1', 'fid': 148}\n",
      "{'video_name': '1', 'fid': 149}\n",
      "{'video_name': '1', 'fid': 150}\n",
      "{'video_name': '1', 'fid': 151}\n",
      "Batch time:  5.557576417922974\n",
      "{'video_name': '1', 'fid': 152}\n",
      "{'video_name': '1', 'fid': 153}\n",
      "{'video_name': '1', 'fid': 154}\n",
      "{'video_name': '1', 'fid': 155}\n",
      "Batch time:  5.4601523876190186\n",
      "{'video_name': '1', 'fid': 156}\n",
      "{'video_name': '1', 'fid': 157}\n",
      "{'video_name': '1', 'fid': 158}\n",
      "{'video_name': '1', 'fid': 159}\n",
      "Batch time:  5.559730291366577\n",
      "{'video_name': '1', 'fid': 160}\n",
      "{'video_name': '1', 'fid': 161}\n",
      "{'video_name': '1', 'fid': 162}\n",
      "{'video_name': '1', 'fid': 163}\n",
      "Batch time:  5.493195533752441\n",
      "{'video_name': '1', 'fid': 164}\n",
      "{'video_name': '1', 'fid': 165}\n",
      "{'video_name': '1', 'fid': 166}\n",
      "{'video_name': '1', 'fid': 167}\n",
      "Batch time:  5.650717496871948\n",
      "{'video_name': '1', 'fid': 168}\n",
      "{'video_name': '1', 'fid': 169}\n",
      "{'video_name': '1', 'fid': 170}\n",
      "{'video_name': '1', 'fid': 171}\n",
      "Batch time:  5.363558053970337\n",
      "{'video_name': '1', 'fid': 172}\n",
      "{'video_name': '1', 'fid': 173}\n",
      "{'video_name': '1', 'fid': 174}\n",
      "{'video_name': '1', 'fid': 175}\n",
      "Batch time:  5.51993465423584\n",
      "{'video_name': '1', 'fid': 176}\n",
      "{'video_name': '1', 'fid': 177}\n",
      "{'video_name': '1', 'fid': 178}\n",
      "{'video_name': '1', 'fid': 179}\n",
      "Batch time:  5.500165700912476\n",
      "{'video_name': '1', 'fid': 180}\n",
      "{'video_name': '1', 'fid': 181}\n",
      "{'video_name': '1', 'fid': 182}\n",
      "{'video_name': '1', 'fid': 183}\n",
      "Batch time:  5.541818141937256\n",
      "{'video_name': '1', 'fid': 184}\n",
      "{'video_name': '1', 'fid': 185}\n",
      "{'video_name': '1', 'fid': 186}\n",
      "{'video_name': '1', 'fid': 187}\n",
      "Batch time:  5.498898267745972\n",
      "{'video_name': '1', 'fid': 188}\n",
      "{'video_name': '1', 'fid': 189}\n",
      "{'video_name': '1', 'fid': 190}\n",
      "{'video_name': '1', 'fid': 191}\n",
      "Batch time:  5.83539605140686\n",
      "{'video_name': '1', 'fid': 192}\n",
      "{'video_name': '1', 'fid': 193}\n",
      "{'video_name': '1', 'fid': 194}\n",
      "{'video_name': '1', 'fid': 195}\n",
      "Batch time:  5.521752834320068\n",
      "{'video_name': '1', 'fid': 196}\n",
      "{'video_name': '1', 'fid': 197}\n",
      "{'video_name': '1', 'fid': 198}\n",
      "{'video_name': '1', 'fid': 199}\n",
      "Batch time:  5.437817573547363\n",
      "{'video_name': '1', 'fid': 200}\n",
      "{'video_name': '1', 'fid': 201}\n",
      "{'video_name': '1', 'fid': 202}\n",
      "{'video_name': '1', 'fid': 203}\n",
      "Batch time:  5.712900400161743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_name': '1', 'fid': 204}\n",
      "{'video_name': '1', 'fid': 205}\n",
      "{'video_name': '1', 'fid': 206}\n",
      "{'video_name': '1', 'fid': 207}\n",
      "Batch time:  5.356975078582764\n",
      "{'video_name': '1', 'fid': 208}\n",
      "{'video_name': '1', 'fid': 209}\n",
      "{'video_name': '1', 'fid': 210}\n",
      "{'video_name': '1', 'fid': 211}\n",
      "Batch time:  5.498437166213989\n",
      "{'video_name': '1', 'fid': 212}\n",
      "{'video_name': '1', 'fid': 213}\n",
      "{'video_name': '1', 'fid': 214}\n",
      "{'video_name': '1', 'fid': 215}\n",
      "Batch time:  5.69699764251709\n",
      "{'video_name': '1', 'fid': 216}\n",
      "{'video_name': '1', 'fid': 217}\n",
      "{'video_name': '1', 'fid': 218}\n",
      "{'video_name': '1', 'fid': 219}\n",
      "Batch time:  5.60590672492981\n",
      "{'video_name': '1', 'fid': 220}\n",
      "{'video_name': '1', 'fid': 221}\n",
      "{'video_name': '1', 'fid': 222}\n",
      "{'video_name': '1', 'fid': 223}\n",
      "Batch time:  5.617249011993408\n",
      "{'video_name': '1', 'fid': 224}\n",
      "{'video_name': '1', 'fid': 225}\n",
      "{'video_name': '1', 'fid': 226}\n",
      "{'video_name': '1', 'fid': 227}\n",
      "Batch time:  5.512809991836548\n",
      "{'video_name': '1', 'fid': 228}\n",
      "{'video_name': '1', 'fid': 229}\n",
      "{'video_name': '1', 'fid': 230}\n",
      "{'video_name': '1', 'fid': 231}\n",
      "Batch time:  5.485130310058594\n",
      "{'video_name': '1', 'fid': 232}\n",
      "{'video_name': '1', 'fid': 233}\n",
      "{'video_name': '1', 'fid': 234}\n",
      "{'video_name': '1', 'fid': 235}\n",
      "Batch time:  5.657757759094238\n",
      "{'video_name': '1', 'fid': 236}\n",
      "{'video_name': '1', 'fid': 237}\n",
      "{'video_name': '1', 'fid': 238}\n",
      "{'video_name': '1', 'fid': 239}\n",
      "Batch time:  6.250194549560547\n",
      "{'video_name': '1', 'fid': 240}\n",
      "{'video_name': '1', 'fid': 241}\n",
      "{'video_name': '1', 'fid': 242}\n",
      "{'video_name': '1', 'fid': 243}\n",
      "Batch time:  5.778805255889893\n",
      "{'video_name': '1', 'fid': 244}\n",
      "{'video_name': '1', 'fid': 245}\n",
      "{'video_name': '1', 'fid': 246}\n",
      "{'video_name': '1', 'fid': 247}\n",
      "Batch time:  5.695801258087158\n",
      "{'video_name': '1', 'fid': 248}\n",
      "{'video_name': '1', 'fid': 249}\n",
      "{'video_name': '1', 'fid': 250}\n",
      "{'video_name': '1', 'fid': 251}\n",
      "Batch time:  5.804331541061401\n",
      "{'video_name': '1', 'fid': 252}\n",
      "{'video_name': '1', 'fid': 253}\n",
      "{'video_name': '1', 'fid': 254}\n",
      "{'video_name': '1', 'fid': 255}\n",
      "Batch time:  5.904059648513794\n",
      "{'video_name': '1', 'fid': 256}\n",
      "{'video_name': '1', 'fid': 257}\n",
      "{'video_name': '1', 'fid': 258}\n",
      "{'video_name': '1', 'fid': 259}\n",
      "Batch time:  5.869655132293701\n",
      "{'video_name': '1', 'fid': 260}\n",
      "{'video_name': '1', 'fid': 261}\n",
      "{'video_name': '1', 'fid': 262}\n",
      "{'video_name': '1', 'fid': 263}\n",
      "Batch time:  5.54374361038208\n",
      "{'video_name': '1', 'fid': 264}\n",
      "{'video_name': '1', 'fid': 265}\n",
      "{'video_name': '1', 'fid': 266}\n",
      "{'video_name': '1', 'fid': 267}\n",
      "Batch time:  5.591102838516235\n",
      "{'video_name': '1', 'fid': 268}\n",
      "{'video_name': '1', 'fid': 269}\n",
      "{'video_name': '1', 'fid': 270}\n",
      "{'video_name': '1', 'fid': 271}\n",
      "Batch time:  5.915711164474487\n",
      "{'video_name': '1', 'fid': 272}\n",
      "{'video_name': '1', 'fid': 273}\n",
      "{'video_name': '1', 'fid': 274}\n",
      "{'video_name': '1', 'fid': 275}\n",
      "Batch time:  5.562129735946655\n",
      "{'video_name': '1', 'fid': 276}\n",
      "{'video_name': '1', 'fid': 277}\n",
      "{'video_name': '1', 'fid': 278}\n",
      "{'video_name': '1', 'fid': 279}\n",
      "Batch time:  5.707195281982422\n",
      "{'video_name': '1', 'fid': 280}\n",
      "{'video_name': '1', 'fid': 281}\n",
      "{'video_name': '1', 'fid': 282}\n",
      "{'video_name': '1', 'fid': 283}\n",
      "Batch time:  5.698474884033203\n",
      "{'video_name': '1', 'fid': 284}\n",
      "{'video_name': '1', 'fid': 285}\n",
      "{'video_name': '1', 'fid': 286}\n",
      "{'video_name': '1', 'fid': 287}\n",
      "Batch time:  5.503596067428589\n",
      "{'video_name': '1', 'fid': 288}\n",
      "{'video_name': '1', 'fid': 289}\n",
      "{'video_name': '1', 'fid': 290}\n",
      "{'video_name': '1', 'fid': 291}\n",
      "Batch time:  5.49198317527771\n",
      "{'video_name': '1', 'fid': 292}\n",
      "{'video_name': '1', 'fid': 293}\n",
      "{'video_name': '1', 'fid': 294}\n",
      "{'video_name': '1', 'fid': 295}\n",
      "Batch time:  5.480082273483276\n",
      "{'video_name': '1', 'fid': 296}\n",
      "{'video_name': '1', 'fid': 297}\n",
      "{'video_name': '1', 'fid': 298}\n",
      "{'video_name': '1', 'fid': 299}\n",
      "Batch time:  5.555260896682739\n",
      "{'video_name': '1', 'fid': 300}\n",
      "{'video_name': '1', 'fid': 301}\n",
      "{'video_name': '1', 'fid': 302}\n",
      "{'video_name': '1', 'fid': 303}\n",
      "Batch time:  5.618648052215576\n",
      "{'video_name': '1', 'fid': 304}\n",
      "{'video_name': '1', 'fid': 305}\n",
      "{'video_name': '1', 'fid': 306}\n",
      "{'video_name': '1', 'fid': 307}\n",
      "Batch time:  5.427236080169678\n",
      "{'video_name': '1', 'fid': 308}\n",
      "{'video_name': '1', 'fid': 309}\n",
      "{'video_name': '1', 'fid': 310}\n",
      "{'video_name': '1', 'fid': 311}\n",
      "Batch time:  5.672206878662109\n",
      "{'video_name': '1', 'fid': 312}\n",
      "{'video_name': '1', 'fid': 313}\n",
      "{'video_name': '1', 'fid': 314}\n",
      "{'video_name': '1', 'fid': 315}\n",
      "Batch time:  5.5521399974823\n",
      "{'video_name': '1', 'fid': 316}\n",
      "{'video_name': '1', 'fid': 317}\n",
      "{'video_name': '1', 'fid': 318}\n",
      "{'video_name': '1', 'fid': 319}\n",
      "Batch time:  5.581269979476929\n",
      "{'video_name': '1', 'fid': 320}\n",
      "{'video_name': '1', 'fid': 321}\n",
      "{'video_name': '1', 'fid': 322}\n",
      "{'video_name': '1', 'fid': 323}\n",
      "Batch time:  5.537947654724121\n",
      "{'video_name': '1', 'fid': 324}\n",
      "{'video_name': '1', 'fid': 325}\n",
      "{'video_name': '1', 'fid': 326}\n",
      "{'video_name': '1', 'fid': 327}\n",
      "Batch time:  5.614387512207031\n",
      "{'video_name': '1', 'fid': 328}\n",
      "{'video_name': '1', 'fid': 329}\n",
      "{'video_name': '1', 'fid': 330}\n",
      "{'video_name': '1', 'fid': 331}\n",
      "Batch time:  5.773201942443848\n",
      "{'video_name': '1', 'fid': 332}\n",
      "{'video_name': '1', 'fid': 333}\n",
      "{'video_name': '1', 'fid': 334}\n",
      "{'video_name': '1', 'fid': 335}\n",
      "Batch time:  5.747881174087524\n",
      "{'video_name': '1', 'fid': 336}\n",
      "{'video_name': '1', 'fid': 337}\n",
      "{'video_name': '1', 'fid': 338}\n",
      "{'video_name': '1', 'fid': 339}\n",
      "Batch time:  5.716724634170532\n",
      "{'video_name': '1', 'fid': 340}\n",
      "{'video_name': '1', 'fid': 341}\n",
      "{'video_name': '1', 'fid': 342}\n",
      "{'video_name': '1', 'fid': 343}\n",
      "Batch time:  5.523133993148804\n",
      "{'video_name': '1', 'fid': 344}\n",
      "{'video_name': '1', 'fid': 345}\n",
      "{'video_name': '1', 'fid': 346}\n",
      "{'video_name': '1', 'fid': 347}\n",
      "Batch time:  5.574727296829224\n",
      "{'video_name': '1', 'fid': 348}\n",
      "{'video_name': '1', 'fid': 349}\n",
      "{'video_name': '1', 'fid': 350}\n",
      "{'video_name': '1', 'fid': 351}\n",
      "Batch time:  5.47312331199646\n",
      "{'video_name': '1', 'fid': 352}\n",
      "{'video_name': '1', 'fid': 353}\n",
      "{'video_name': '1', 'fid': 354}\n",
      "{'video_name': '1', 'fid': 355}\n",
      "Batch time:  5.838768005371094\n",
      "{'video_name': '1', 'fid': 356}\n",
      "{'video_name': '1', 'fid': 357}\n",
      "{'video_name': '1', 'fid': 358}\n",
      "{'video_name': '1', 'fid': 359}\n",
      "Batch time:  6.11688756942749\n",
      "{'video_name': '1', 'fid': 360}\n",
      "{'video_name': '1', 'fid': 361}\n",
      "{'video_name': '1', 'fid': 362}\n",
      "{'video_name': '1', 'fid': 363}\n",
      "Batch time:  5.612875461578369\n",
      "{'video_name': '1', 'fid': 364}\n",
      "{'video_name': '1', 'fid': 365}\n",
      "{'video_name': '1', 'fid': 366}\n",
      "{'video_name': '1', 'fid': 367}\n",
      "Batch time:  5.860442161560059\n",
      "{'video_name': '1', 'fid': 368}\n",
      "{'video_name': '1', 'fid': 369}\n",
      "{'video_name': '1', 'fid': 370}\n",
      "{'video_name': '1', 'fid': 371}\n",
      "Batch time:  5.404681921005249\n",
      "{'video_name': '1', 'fid': 372}\n",
      "{'video_name': '1', 'fid': 373}\n",
      "{'video_name': '1', 'fid': 374}\n",
      "{'video_name': '1', 'fid': 375}\n",
      "Batch time:  5.665916442871094\n",
      "{'video_name': '1', 'fid': 376}\n",
      "{'video_name': '1', 'fid': 377}\n",
      "{'video_name': '1', 'fid': 378}\n",
      "{'video_name': '1', 'fid': 379}\n",
      "Batch time:  5.546186923980713\n",
      "{'video_name': '1', 'fid': 380}\n",
      "{'video_name': '1', 'fid': 381}\n",
      "{'video_name': '1', 'fid': 382}\n",
      "{'video_name': '1', 'fid': 383}\n",
      "Batch time:  5.5793373584747314\n",
      "{'video_name': '1', 'fid': 384}\n",
      "{'video_name': '1', 'fid': 385}\n",
      "{'video_name': '1', 'fid': 386}\n",
      "{'video_name': '1', 'fid': 387}\n",
      "Batch time:  5.40227746963501\n",
      "{'video_name': '1', 'fid': 388}\n",
      "{'video_name': '1', 'fid': 389}\n",
      "{'video_name': '1', 'fid': 390}\n",
      "{'video_name': '1', 'fid': 391}\n",
      "Batch time:  5.482304573059082\n",
      "{'video_name': '1', 'fid': 392}\n",
      "{'video_name': '1', 'fid': 393}\n",
      "{'video_name': '1', 'fid': 394}\n",
      "{'video_name': '1', 'fid': 395}\n",
      "Batch time:  5.50309419631958\n",
      "{'video_name': '1', 'fid': 396}\n",
      "{'video_name': '1', 'fid': 397}\n",
      "{'video_name': '1', 'fid': 398}\n",
      "{'video_name': '1', 'fid': 399}\n",
      "Batch time:  5.812175750732422\n",
      "{'video_name': '1', 'fid': 400}\n",
      "{'video_name': '1', 'fid': 401}\n",
      "{'video_name': '1', 'fid': 402}\n",
      "{'video_name': '1', 'fid': 403}\n",
      "Batch time:  5.506614446640015\n",
      "{'video_name': '1', 'fid': 404}\n",
      "{'video_name': '1', 'fid': 405}\n",
      "{'video_name': '1', 'fid': 406}\n",
      "{'video_name': '1', 'fid': 407}\n",
      "Batch time:  5.515268802642822\n",
      "{'video_name': '1', 'fid': 408}\n",
      "{'video_name': '1', 'fid': 409}\n",
      "{'video_name': '1', 'fid': 410}\n",
      "{'video_name': '1', 'fid': 411}\n",
      "Batch time:  5.553555727005005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_name': '1', 'fid': 412}\n",
      "{'video_name': '1', 'fid': 413}\n",
      "{'video_name': '1', 'fid': 414}\n",
      "{'video_name': '1', 'fid': 415}\n",
      "Batch time:  5.525321006774902\n",
      "{'video_name': '1', 'fid': 416}\n",
      "{'video_name': '1', 'fid': 417}\n",
      "{'video_name': '1', 'fid': 418}\n",
      "{'video_name': '1', 'fid': 419}\n",
      "Batch time:  5.447018146514893\n",
      "{'video_name': '1', 'fid': 420}\n",
      "{'video_name': '1', 'fid': 421}\n",
      "{'video_name': '1', 'fid': 422}\n",
      "{'video_name': '1', 'fid': 423}\n",
      "Batch time:  5.626657009124756\n",
      "{'video_name': '1', 'fid': 424}\n",
      "{'video_name': '1', 'fid': 425}\n",
      "{'video_name': '1', 'fid': 426}\n",
      "{'video_name': '1', 'fid': 427}\n",
      "Batch time:  5.850473403930664\n",
      "{'video_name': '1', 'fid': 428}\n",
      "{'video_name': '1', 'fid': 429}\n",
      "{'video_name': '1', 'fid': 430}\n",
      "{'video_name': '1', 'fid': 431}\n",
      "Batch time:  6.294144868850708\n",
      "{'video_name': '1', 'fid': 432}\n",
      "{'video_name': '1', 'fid': 433}\n",
      "{'video_name': '1', 'fid': 434}\n",
      "{'video_name': '1', 'fid': 435}\n",
      "Batch time:  5.644746780395508\n",
      "{'video_name': '1', 'fid': 436}\n",
      "{'video_name': '1', 'fid': 437}\n",
      "{'video_name': '1', 'fid': 438}\n",
      "{'video_name': '1', 'fid': 439}\n",
      "Batch time:  5.561939477920532\n",
      "{'video_name': '1', 'fid': 440}\n",
      "{'video_name': '1', 'fid': 441}\n",
      "{'video_name': '1', 'fid': 442}\n",
      "{'video_name': '1', 'fid': 443}\n",
      "Batch time:  5.454549789428711\n",
      "{'video_name': '1', 'fid': 444}\n",
      "{'video_name': '1', 'fid': 445}\n",
      "{'video_name': '1', 'fid': 446}\n",
      "{'video_name': '1', 'fid': 447}\n",
      "Batch time:  5.41220235824585\n",
      "{'video_name': '1', 'fid': 448}\n",
      "{'video_name': '1', 'fid': 449}\n",
      "{'video_name': '1', 'fid': 450}\n",
      "{'video_name': '1', 'fid': 451}\n",
      "Batch time:  5.443773984909058\n",
      "{'video_name': '1', 'fid': 452}\n",
      "{'video_name': '1', 'fid': 453}\n",
      "{'video_name': '1', 'fid': 454}\n",
      "{'video_name': '1', 'fid': 455}\n",
      "Batch time:  5.3667356967926025\n",
      "{'video_name': '1', 'fid': 456}\n",
      "{'video_name': '1', 'fid': 457}\n",
      "{'video_name': '1', 'fid': 458}\n",
      "{'video_name': '1', 'fid': 459}\n",
      "Batch time:  5.4488184452056885\n",
      "{'video_name': '1', 'fid': 460}\n",
      "{'video_name': '1', 'fid': 461}\n",
      "{'video_name': '1', 'fid': 462}\n",
      "{'video_name': '1', 'fid': 463}\n",
      "Batch time:  5.4666008949279785\n",
      "{'video_name': '1', 'fid': 464}\n",
      "{'video_name': '1', 'fid': 465}\n",
      "{'video_name': '1', 'fid': 466}\n",
      "{'video_name': '1', 'fid': 467}\n",
      "Batch time:  5.661136865615845\n",
      "{'video_name': '1', 'fid': 468}\n",
      "{'video_name': '1', 'fid': 469}\n",
      "{'video_name': '1', 'fid': 470}\n",
      "{'video_name': '1', 'fid': 471}\n",
      "Batch time:  5.439269542694092\n",
      "{'video_name': '1', 'fid': 472}\n",
      "{'video_name': '1', 'fid': 473}\n",
      "{'video_name': '1', 'fid': 474}\n",
      "{'video_name': '1', 'fid': 475}\n",
      "Batch time:  5.549524784088135\n",
      "{'video_name': '1', 'fid': 476}\n",
      "{'video_name': '1', 'fid': 477}\n",
      "{'video_name': '1', 'fid': 478}\n",
      "{'video_name': '1', 'fid': 479}\n",
      "Batch time:  5.376441717147827\n",
      "{'video_name': '1', 'fid': 480}\n",
      "{'video_name': '1', 'fid': 481}\n",
      "{'video_name': '1', 'fid': 482}\n",
      "{'video_name': '1', 'fid': 483}\n",
      "Batch time:  5.666296720504761\n",
      "{'video_name': '1', 'fid': 484}\n",
      "{'video_name': '1', 'fid': 485}\n",
      "{'video_name': '1', 'fid': 486}\n",
      "{'video_name': '1', 'fid': 487}\n",
      "Batch time:  5.421130418777466\n",
      "{'video_name': '1', 'fid': 488}\n",
      "{'video_name': '1', 'fid': 489}\n",
      "{'video_name': '1', 'fid': 490}\n",
      "{'video_name': '1', 'fid': 491}\n",
      "Batch time:  5.528470039367676\n",
      "{'video_name': '1', 'fid': 492}\n",
      "{'video_name': '1', 'fid': 493}\n",
      "{'video_name': '1', 'fid': 494}\n",
      "{'video_name': '1', 'fid': 495}\n",
      "Batch time:  5.72301721572876\n"
     ]
    }
   ],
   "source": [
    "%run -i demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33bf21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python [conda env:ict3104]",
   "language": "python",
   "name": "conda-env-ict3104-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ebacec254d4e7a6363c1bc7ffc0d93a067b75c23c5ab80637754c15d5815670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

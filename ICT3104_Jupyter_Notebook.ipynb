{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c205650",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae75fb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload File using ipyfilechooser library\n",
    "from ipyfilechooser import FileChooser\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time \n",
    "# Get the root directory of the project\n",
    "from pyprojroot import here\n",
    "# Copy File\n",
    "import shutil\n",
    "# Widget Packages\n",
    "import ipywidgets as widgets\n",
    "# In case widget extension not working\n",
    "# jupyter nbextension enable --py widgetsnbextension\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b99c7",
   "metadata": {},
   "source": [
    "# Data Exploration Section\n",
    "R2 (Epic): As a user, I want a \"Data Exploration\" section in the notebook so that I can load and display video data from the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed518c9e",
   "metadata": {},
   "source": [
    "## Video Upload / Choose using ipyfilechooser\n",
    "R2 (Story): As a user, I want to upload/choose files from the data folder through an appropriate UI component (E.g. Browse files) in a notebook code cell so that I can pick and choose the video data I would like to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7459f1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def videoselectorinput():\n",
    "    starting_directory = './data/video'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "def videoselectoroutput():\n",
    "    starting_directory = './pipeline/video/output'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9251f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9761f",
   "metadata": {},
   "source": [
    "## Upload selected video to the data folder (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdc476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload Function\n",
    "# from pyprojroot import here\n",
    "# import shutil\n",
    "def upload(video):\n",
    "    print(video.selected)\n",
    "    source = video.selected\n",
    "    # Source path\n",
    "    # Destination path\n",
    "    destination = (here(\"./data/video\"))\n",
    "\n",
    "    # Copy file from the selected path\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        print(\"File copied successfully.\")\n",
    "\n",
    "    # If source and destination are same\n",
    "    except shutil.SameFileError:\n",
    "        print(\"Source and destination represents the same file.\")\n",
    "\n",
    "    # If destination is a directory.\n",
    "    except IsADirectoryError:\n",
    "        print(\"Destination is a directory.\")\n",
    "\n",
    "    # If there is any permission issue\n",
    "    except PermissionError:\n",
    "        print(\"Permission denied.\")\n",
    "\n",
    "    # For other errors\n",
    "    except:\n",
    "        print(\"Error occurred while copying file.\")\n",
    "\n",
    "upload(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd190ad",
   "metadata": {},
   "source": [
    "## Video Playback\n",
    "R2 (Story): As a user, I want to see video playback of the chosen video file in an output cell so that I can check if it is the right video data I would like to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce6882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Video\n",
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d5e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(video.selected)\n",
    "print(video.selected_filename)\n",
    "print(video.selected_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09127163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "full_path = video.selected\n",
    "Video(full_path, embed=True, width=540, html_attributes=\"controls muted autoplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51191d83",
   "metadata": {},
   "source": [
    "# Inference Section\n",
    "\n",
    "R3 (Epic): As a user, I want to have an \"Inference\" section in the notebook so that I can perform inference using a pretrained HOI ML model based on the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e20405",
   "metadata": {},
   "source": [
    "# Run_PDAN\n",
    "R3 (Story): As a user, I want to able to change the value for the argument in run_PDAN shell script with a UI so that I does not need to keep changing the value directly in the shell script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d10fe28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f58340cae00462c95d0943505cd4136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Run_PDAN')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56566a29a245e2a813bd001cbb3229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='TSU', description='Dataset:', placeholder='Enter Dataset Name', style=TextStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d18d65b296498589f399c0a47adb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='rgb', description='Mode:', placeholder='Enter Mode', style=TextStyle(description_width='90px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efbed26f1364e3da290f34b42fd5755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='CS', description='Split Setting:', placeholder='Enter Split Setting', style=TextStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe38c8557144997aeabcc69993c1a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='PDAN_TSU_RGB', description='Model:', placeholder='Enter Model Name', style=TextStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744a6e16db6f43efaa52d58123aa0c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Train', style=CheckboxStyle(description_width='90px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a4c26d21f24d7381da808c7f06fdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=512, description='Num Channel:', max=1000, min=1, style=DescriptionStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17cf09bbd11412bb4b0378b59668c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0002, description='Learning Rate:', style=DescriptionStyle(description_width='90px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732d1a2c10dd484da32c1067b2b9b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=3, description='Kernel Size:', max=5, min=1, style=DescriptionStyle(description_width='90…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7861860f296441c6882b658ba9679435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='map', description='APType:', placeholder='Enter APType', style=TextStyle(description_width='90px')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3822e0097ccd484abcd5675fc69f7a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=140, description='Epoch:', max=1000, min=1, style=DescriptionStyle(description_width='90p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383606e2c02c48dca958e65897bd70e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Batch_Size:', options=('1', '2', '4', '8', '16', '32', '64', '128', '256', '512', '1024'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f8fb2eba54d55844398c8b22c213f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='TSU_CS_RGB_PDAN', description='Compute Info:', placeholder='Enter Compute Info', style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487cd875931145c4ae5cc8d8f756b1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save', icon='check', style=ButtonStyle(), tooltip='Save Pref')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Dataset:  TSU\n",
      "Selected Mode:  rgb\n",
      "Selected Split Setting:  CS\n",
      "Selected Model:  PDAN_TSU_RGB\n",
      "Selected Train:  False\n",
      "Selected Num Channel:  512\n",
      "Selected Learning Rate:  0.0002\n",
      "Selected Kernel Size:  3\n",
      "Selected APType:  map\n",
      "Selected Epoch:  140\n",
      "Selected Batch:  1\n",
      "Selected Compute Info:  TSU_CS_RGB_PDAN\n",
      "C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\pipeline\n",
      "Random_SEED!!!: 0\n",
      "PDAN_TSU_RGB\n",
      "batch_size: 1\n",
      "cuda_avail True\n",
      "File name:  P02T0\n",
      "FilePath:  ../data/P02T04C05.mp4\n",
      "Model:  PDAN_TSU_RGB\n",
      "Load Model ./models/PDAN_TSU_RGB\n",
      "RGB mode ./data/RGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 536/536 [00:05<00:00, 104.10it/s]\n",
      "100%|██████████| 536/536 [00:02<00:00, 184.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are processing PDAN_TSU_RGB\n",
      "loaded ./models/PDAN_TSU_RGB\n",
      "pytorch_total_params 5804083\n",
      "num_channel: 512 input_channnel: 1024 num_classes: 51\n",
      "0.0002\n",
      "True\n",
      "Epoch 0/139\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\pipeline\\test.py:494\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28mprint\u001B[39m(args\u001B[38;5;241m.\u001B[39mtest)\n\u001B[0;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mtest:\n\u001B[1;32m--> 494\u001B[0m     \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_sched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomp_info\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    496\u001B[0m     val_file([(model, \u001B[38;5;241m0\u001B[39m, dataloaders, optimizer, lr_sched, args\u001B[38;5;241m.\u001B[39mcomp_info)], num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(args\u001B[38;5;241m.\u001B[39mepoch))\n",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\pipeline\\test.py:211\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(models, criterion, num_epochs)\u001B[0m\n\u001B[0;32m    207\u001B[0m probs \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, gpu, dataloader, optimizer, sched, model_file \u001B[38;5;129;01min\u001B[39;00m models:\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;66;03m# Comment out the following line to train the model since using pre train model.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;66;03m# train_map, train_loss = train_step(model, gpu, optimizer, dataloader['train'], epoch)\u001B[39;00m\n\u001B[1;32m--> 211\u001B[0m     prob_val, val_loss, val_map \u001B[38;5;241m=\u001B[39m \u001B[43mval_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m     probs\u001B[38;5;241m.\u001B[39mappend(prob_val)\n\u001B[0;32m    213\u001B[0m     sched\u001B[38;5;241m.\u001B[39mstep(val_loss)\n",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\pipeline\\test.py:315\u001B[0m, in \u001B[0;36mval_step\u001B[1;34m(model, gpu, dataloader, epoch)\u001B[0m\n\u001B[0;32m    312\u001B[0m full_probs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# Iterate over data.\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m    316\u001B[0m     num_iter \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    317\u001B[0m     other \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m3\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:359\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:305\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Projects\\ict3104-team05-2022\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:918\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    911\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    912\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m    915\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m    917\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m--> 918\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:326\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "title = widgets.Label(\"Run_PDAN\")\n",
    "style = {'description_width': '90px'}\n",
    "\n",
    "dataset_input = widgets.Text(\n",
    "    value='TSU',\n",
    "    placeholder='Enter Dataset Name',\n",
    "    description='Dataset:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "mode_input = widgets.Text(\n",
    "    value='rgb',\n",
    "    placeholder='Enter Mode',\n",
    "    description='Mode:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "split_input = widgets.Text(\n",
    "    value='CS',\n",
    "    placeholder='Enter Split Setting',\n",
    "    description='Split Setting:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "model_input = widgets.Text(\n",
    "    value='PDAN_TSU_RGB',\n",
    "    placeholder='Enter Model Name',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "train_input = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description = 'Train',\n",
    "    disabled=False,\n",
    "    indent=True,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "num_channel_input =  widgets.BoundedIntText(\n",
    "    value=512,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Num Channel:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "lr_input = widgets.FloatText(\n",
    "    value=0.0002,\n",
    "    description='Learning Rate:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "kernel_size_input =  widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=5,\n",
    "    step=1,\n",
    "    description='Kernel Size:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "aptype_input = widgets.Text(\n",
    "    value='map',\n",
    "    placeholder='Enter APType',\n",
    "    description='APType:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "epoch_input = widgets.BoundedIntText(\n",
    "    value=140,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Epoch:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "batch_size_input = widgets.Dropdown(\n",
    "    options=['1', '2', '4', '8', '16', '32', '64', '128', '256', '512', '1024'],\n",
    "    value='1',\n",
    "    description='Batch_Size:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "\n",
    "comp_info_input = widgets.Text(\n",
    "    value='TSU_CS_RGB_PDAN',\n",
    "    placeholder='Enter Compute Info',\n",
    "    description='Compute Info:',\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Save',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Save Pref',\n",
    "    icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "    style=style\n",
    ")\n",
    "\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected Dataset: \" , dataset_input.value)\n",
    "    print(\"Selected Mode: \" , mode_input.value)\n",
    "    print(\"Selected Split Setting: \" , split_input.value)\n",
    "    print(\"Selected Model: \" , model_input.value)\n",
    "    print(\"Selected Train: \" , train_input.value)\n",
    "    print(\"Selected Num Channel: \" , num_channel_input.value)\n",
    "    print(\"Selected Learning Rate: \" , lr_input.value)\n",
    "    print(\"Selected Kernel Size: \" , kernel_size_input.value)\n",
    "    print(\"Selected APType: \", aptype_input.value)\n",
    "    print(\"Selected Epoch: \", epoch_input.value)\n",
    "    print(\"Selected Batch: \" , batch_size_input.value)\n",
    "    print(\"Selected Compute Info: \" , comp_info_input.value)\n",
    "    path =here(\"./pipeline\")\n",
    "    %cd $path\n",
    "    %run -i test.py -dataset $dataset_input.value -mode $mode_input.value -split_setting $split_input.value -model $model_input.value -train $train_input.value -num_channel $num_channel_input.value -lr $lr_input.value -kernelsize $kernel_size_input.value -APtype $aptype_input.value -epoch $epoch_input.value -batch_size $batch_size_input.value -comp_info $comp_info_input.value -test True\n",
    "\n",
    "display(title, dataset_input, mode_input,split_input, model_input , train_input, num_channel_input, lr_input, kernel_size_input, aptype_input, epoch_input, batch_size_input, comp_info_input ,button)\n",
    "button.on_click(selectWidgetSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b56cd",
   "metadata": {},
   "source": [
    "## Load a pretrain model\n",
    "R3 (Story): As a user, I want to load a pre-trained model using an appropriate UI component so that I can easily load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263f4135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3b3ca3bde440299fa8dc160df03b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Model:', options=('PDAN_TSU_RGB', 'test'), value='PDAN_TSU…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected:  PDAN_TSU_RGB\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "path =here()\n",
    "os.chdir(path)\n",
    "modelList = [] \n",
    "\n",
    "# Select from the list of model in the pipeline/models folder\n",
    "for x in os.listdir(\"./pipeline/models\"): \n",
    "    modelList += [x]\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "modelDropdown = widgets.Dropdown(\n",
    "    options=modelList,\n",
    "    value=modelList[0],\n",
    "    description='Model:')\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected: \" , modelDropdown.value)\n",
    "\n",
    "confirmButton.on_click(selectWidgetSet)\n",
    "modelBox = widgets.VBox([widgets.HBox([modelDropdown, confirmButton])])\n",
    "modelBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad9e82",
   "metadata": {},
   "source": [
    "## Choose Input video to load into TSU Project\n",
    "R3 (Story): As a user, I want to choose an  input video files and other related input files, using an appropriate UI component, from the TSU project so that the system is able to pass the right files to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a7e1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e913959b910464c94a5d21db78ed512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\data\\video', filename='', title='', show_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select Video\n",
    "video = videoselectorinput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8854da",
   "metadata": {},
   "source": [
    "## Run the model \n",
    "R3 (Story): As a user, I want to see inference results in the form of an output video with captions that indicate the current detected activity in each video frame so that I am able to see the inference results clearly on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5f2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\pipeline\n",
      "P02T05C05.mp4\n",
      "C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\data\\testing\\P02T05C05.mp4\n",
      "Random_SEED!!!: 0\n",
      "PDAN_TSU_RGB\n",
      "batch_size: 2\n",
      "cuda_avail True\n",
      "File name:  P02T05C05\n",
      "FilePath:  C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\data\\testing\\P02T05C05.mp4\n",
      "Model:  PDAN_TSU_RGB\n",
      "Load Model ./models/PDAN_TSU_RGB\n",
      "RGB mode ./data/RGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 536/536 [00:05<00:00, 105.36it/s]\n",
      "100%|██████████| 536/536 [00:02<00:00, 187.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are processing PDAN_TSU_RGB\n",
      "loaded ./models/PDAN_TSU_RGB\n",
      "pytorch_total_params 5804083\n",
      "num_channel: 512 input_channnel: 1024 num_classes: 51\n",
      "0.1\n",
      "False\n",
      "val-map: tensor(32.7511)\n",
      "tensor([43.9296, 50.4119, 45.0844, 45.3014, 40.5055, 43.5343, 33.3114, 30.4521,\n",
      "        40.9460, 20.7510, 17.2716,  5.1264,  0.7856, 38.4160, 37.8608,  3.3669,\n",
      "        22.8392, 56.7582,  2.8444, 72.0715, 33.0098, 52.9259, 52.4670,  3.2723,\n",
      "         1.6550, 63.7364, 37.0699, 52.0327, 60.0214, 15.2961,  6.6451,  0.8588,\n",
      "        39.0778,  2.8659, 48.3819, 89.2970, 37.7782, 15.1304, 23.2170,  8.0989,\n",
      "        70.3756, 32.7410, 17.4085, 64.6966,  2.0250, 76.3004, 65.2976, 32.5429,\n",
      "        11.6490,  2.2110,  0.6536])\n",
      "video is:  C:\\Users\\Work\\Desktop\\Projects\\ict3104-team05-2022\\data\\testing\\P02T05C05.mp4\n",
      "cap is:  < cv2.VideoCapture 0000021818B0A330>\n",
      "Len 1419\n",
      "No:  22697.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating video:.... 4391:  19%|█▉        | 4390/22697 [01:08<04:46, 63.94it/s]"
     ]
    }
   ],
   "source": [
    "path =here(\"./pipeline\")\n",
    "%cd $path\n",
    "model = modelDropdown.value\n",
    "loadmodel = './models/' + model\n",
    "videoPath = video.selected\n",
    "videoFile = video.selected_filename\n",
    "print(videoFile)\n",
    "print(videoPath)\n",
    "%run -it test.py  -input_video_file $videoFile -model $model  -load_mode $loadmodel -video_path $videoPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326ce9c",
   "metadata": {},
   "source": [
    "## Output Video to view the inference result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb7c95",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "full_path = (os.path.join(here(\"./pipeline/video/output/\"),\"P02T05C05_caption.mp4\"))\n",
    "# full_path = video.selected\n",
    "Video(full_path, embed=True, width=640, html_attributes=\"controls muted autoplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67463a88",
   "metadata": {},
   "source": [
    "# Training Section\n",
    "R4 (Epic): As a user, I want to create a \"Training\" section in the netbook so that I can train a HOI ML model based on the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70406aa5",
   "metadata": {},
   "source": [
    "## Choose dataset folder to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a634a8",
   "metadata": {},
   "source": [
    "R4 (Story): As a user, I can choose a dataset subfolder, using appropriate UI elements, from the data folder to use for the training so that I can select the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee4e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Dropdown method\n",
    "dataset_list = []\n",
    "directoryDataset = \"./data/dataset/\" # Directory of the dataset (NPY files)\n",
    "\n",
    "# Store the folder in the  dataset into dataset list\n",
    "for x in os.listdir(directoryDataset):\n",
    "    if os.path.isdir(os.path.join(directoryDataset, x)):\n",
    "        # print(os.path.join(directoryDataset, x))\n",
    "        dataset_list.append(x)\n",
    "\n",
    "datasetDropDown = widgets.Dropdown(\n",
    "    options=dataset_list,\n",
    "    description='Dataset:')\n",
    "\n",
    "# Widgets\n",
    "datasetConfirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectDataSet(b):\n",
    "    print(\"Selected Dataset: \" , datasetDropDown.value)\n",
    "   \n",
    "datasetConfirmButton.on_click(selectDataSet)\n",
    "datasetBox = widgets.VBox([widgets.HBox([datasetDropDown, datasetConfirmButton])])\n",
    "datasetBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b18eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Browse folder method\n",
    "def folderSelector():\n",
    "    starting_directory = './data/dataset'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    chooser.show_only_dirs = True\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "\n",
    "datafolder = folderSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d60d71",
   "metadata": {},
   "source": [
    "R4 (Story): As a user, I can add the trained model to the list of pre-trained models that can be chosen in R3 after its training so that I can add my trained model to pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_list = ['Add', 'Remove']\n",
    "\n",
    "confirmChangeButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "modelChangeDropDown = widgets.Dropdown(\n",
    "    options=change_list,\n",
    "    description='Add/Remove: ')\n",
    "\n",
    "def selectChangeSet(b):\n",
    "    global choice\n",
    "    choice = modelChangeDropDown.value\n",
    "    print(\"Selected: \" , modelChangeDropDown.value)\n",
    "    \n",
    "confirmChangeButton.on_click(selectChangeSet)\n",
    "display(modelChangeDropDown, confirmChangeButton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af76479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addModel():\n",
    "    starting_directory = '.'\n",
    "    chooser = FileChooser(starting_directory)\n",
    "    display(chooser)\n",
    "    return chooser\n",
    "\n",
    "#pretrained_models = ['TSU_', 'NVIDIA Setp Model']\n",
    "pretrained_models = []\n",
    "\n",
    "add_model = addModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_file(add_model):\n",
    "    if add_model.selected_filename == None:\n",
    "        return  ''\n",
    "    else:\n",
    "        from pathlib import Path\n",
    "        file_name = Path(add_model.selected_filename).stem\n",
    "        return file_name\n",
    "    \n",
    "file_name = selected_file (add_model)\n",
    "\n",
    "#models_list = ['TSU', 'NVIDIA Set Model']\n",
    "models_list = []\n",
    "\n",
    "def checkExist(filename):\n",
    "    with open('models_list.txt', 'r') as f:\n",
    "        if filename in f.read():\n",
    "            f.close()\n",
    "            return True\n",
    "        else:\n",
    "            f.close()\n",
    "            return False\n",
    "        \n",
    "def addToList(filename):\n",
    "    if checkExist(filename):\n",
    "        print(filename, \" already exist\")\n",
    "    else:\n",
    "         with open('models_list.txt', 'a') as f:\n",
    "            f.write(filename + \"\\n\")\n",
    "            \n",
    "def removeFromList(filename):\n",
    "    if checkExist(filename):\n",
    "        with open('models_list.txt', 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "\n",
    "        # Delete text and Write\n",
    "        with open('models_list.txt', 'w') as file:\n",
    "            # Delete\n",
    "            new_text = text.replace(filename, '')\n",
    "            # Write\n",
    "            file.write(new_text)\n",
    "    else:\n",
    "        print(filename, \" does not exist\")\n",
    "    \n",
    "    \n",
    "if choice == 'Add':\n",
    "    addToList(file_name)\n",
    "elif choice == 'Remove':\n",
    "    removeFromList(file_name)\n",
    "else:\n",
    "    print('Invalid choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba99aa7",
   "metadata": {},
   "source": [
    "# Testing Section\n",
    "R5 (Epic): As a user, I want to have a \"Testing\" section in the notebook so that I can evaluate a trained model based on the TSU project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bfc3b",
   "metadata": {},
   "source": [
    "R5 (Story): As a user, I want to load a pretrained model using an appropriate UI component so that I can easily choose the type of pretrained model I would like to process the data with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select the model\n",
    "\"\"\"\n",
    "modelList = [] \n",
    "\n",
    "# Select from the list of model in the pipeline/models folder\n",
    "for x in os.listdir(\"./pipeline/models\"): \n",
    "    modelList += [x]\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "modelDropdown = widgets.Dropdown(\n",
    "    options=modelList,\n",
    "    value=modelList[0],\n",
    "    description='Model:')\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectWidgetSet(b):\n",
    "    print(\"Selected: \" , modelDropdown.value)\n",
    "\n",
    "confirmButton.on_click(selectWidgetSet)\n",
    "modelBox = widgets.VBox([widgets.HBox([modelDropdown, confirmButton])])\n",
    "modelBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143aac1",
   "metadata": {},
   "source": [
    "# NVIDIA STEP Section\n",
    "R6 (Epic): As a user, I want to able to configure the notebook using appropriate UI elements coupled with the right .py modules so that R2-5 can be performed based on another pipeline, e.g., the NVIDIA STEP pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd71b6b",
   "metadata": {},
   "source": [
    "## Pipeline Selection\n",
    "R6(Story): As a user, I want to create appropriate UI elements to allow for switching pipelines so that I can test the different models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ee99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=['TSU', 'NVIDIA SMarthome'],\n",
    "    value='TSU',\n",
    "    description='Pipeline:',\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        print(\"changed to %s\" % change['new'])\n",
    "\n",
    "w.observe(on_change)\n",
    "\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58612b38",
   "metadata": {},
   "source": [
    "## Nvidia Step Pipeline\n",
    "R6(Story): As a user, I want to ensure selected pipeline's dependencies are changed to ensure the right dependencies are given to the appropriate models so that the selected model will be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b4e04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd ../NVIDIA-STEP-MODEL/STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8801f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ipython setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176b4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf4465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='datasets/demo/frames/results/2/frame0000.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d92d7",
   "metadata": {},
   "source": [
    "T05-119 As a user, I want to have multiple dropdowns to select the input (1) dataset (2) video so that I can select the dataset videos easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18281ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select video\n",
    "video_list = [] \n",
    "dataset_list = [] \n",
    "directoryVideo = \"./data/video/\" # Directory of the video (.mp4)\n",
    "directoryDataset = \"./data/dataset/\" # Directory of the dataset (NPY files)\n",
    "\n",
    "# Store the folder in the  dataset into dataset list\n",
    "for x in os.listdir(directoryDataset):\n",
    "    if os.path.isdir(os.path.join(directoryDataset, x)):\n",
    "        # print(os.path.join(directoryDataset, x))\n",
    "        dataset_list.append(x)\n",
    "\n",
    "# Store the video names into video list\n",
    "for x in os.listdir(directoryVideo):\n",
    "    if x.endswith(\".mp4\"):\n",
    "        video_list.append(x)\n",
    "\n",
    "datasetDropDown = widgets.Dropdown(\n",
    "    options=dataset_list,\n",
    "    description='Dataset:')\n",
    "\n",
    "videoDropDown = widgets.Dropdown(\n",
    "    options=video_list,\n",
    "    description='Video: ')\n",
    "\n",
    "# Widgets\n",
    "confirmButton = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='check'\n",
    ")\n",
    "# Function on what happen when confirm is been click.\n",
    "def selectTrimSet(b):\n",
    "    print(\"Selected Dataset: \" , datasetDropDown.value)\n",
    "    print(\"Selected Video: \" , videoDropDown.value)\n",
    "\n",
    "confirmButton.on_click(selectTrimSet)\n",
    "display(datasetDropDown, videoDropDown, confirmButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050f788",
   "metadata": {},
   "source": [
    "T05-127 As a User, I want the output of Nvidia STEP model to be in a video format, So that I can easily view the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfaaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1676bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install os-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07118aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "for filename in glob.glob('datasets/demo/frames/1/*.jpg'):\n",
    "    img = cv2.imread(filename) \n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('Output/project.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522fe71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "21443173980de8f8bd52f0a8d21aa24ff048531cbf1e79ef9f1f2c09c5456057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
